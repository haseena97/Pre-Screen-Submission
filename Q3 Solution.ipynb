{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f879ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# cleaning data \n",
    "import re\n",
    "# for division\n",
    "from operator import truediv\n",
    "# to multiply all element in the list\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b3e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the text line by line into list\n",
    "with open('C:/Users/Acer/Downloads/pre-screen/text/poco.txt', 'r') as f:\n",
    "    lines_list = [] # buant container kosong\n",
    "    for line in f:\n",
    "        lines_list.append(line.strip()) # line.strip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11e4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted symbols if exists\n",
    "def cleaning_text(i):\n",
    "    i = re.sub(\"[^A-Za-z\" \"]+\",\" \",i).lower() #buang punctuation\n",
    "    i = re.sub(\"[0-9\" \"]+\",\" \",i)\n",
    "    w = []\n",
    "    for word in i.split(\" \"):\n",
    "        if len(word)>3: # remove joint word\n",
    "            w.append(word)\n",
    "    return (\" \".join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c227d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_list2 = [cleaning_text(item) for item in  lines_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fee082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of of the word “data” occurring for each line is : [0.1, 0.0, 0.0, 0.09090909090909091, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1111111111111111, 0.0, 0.1, 0.16666666666666666, 0.2222222222222222, 0.1111111111111111, 0.0, 0.18181818181818182, 0.2, 0.1, 0.0, 0.09090909090909091, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Q1: count probability of the word 'data' occuring in each line\n",
    "# count occurrence of 'data' in each line\n",
    "nm = 'data'\n",
    "occurences = [item.count(nm) for item in  lines_list2]\n",
    "count = sum(occurences)\n",
    "#print(occurences) # This will print out all occurences of input string\n",
    "#print('count = ', count) \n",
    "# count total words in each line\n",
    "total_word = []\n",
    "for x,word in enumerate(lines_list2):\n",
    "    num = (len(word.split()))\n",
    "    total_word.append(num)\n",
    "# probability of word 'data' occuring in each line\n",
    "prob = list(map(truediv, occurences, total_word))\n",
    "print (\"The probability of of the word “data” occurring for each line is : \" + str(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8606745e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 3, 'data': 18, 'analytics': 10, 'predominantly': 1, 'refers': 1, 'assortment': 1, 'applications': 1, 'from': 2, 'basic': 1, 'business': 4, 'intelligence': 1, 'reporting': 1, 'online': 1, 'analytical': 1, 'processing': 1, 'olap': 1, 'various': 1, 'forms': 1, 'advanced': 2, 'that': 5, 'sense': 1, 'similar': 1, 'nature': 1, 'another': 1, 'umbrella': 1, 'approaches': 1, 'analyzing': 1, 'with': 3, 'difference': 1, 'latter': 1, 'oriented': 1, 'uses': 2, 'while': 2, 'broader': 1, 'focus': 1, 'expansive': 1, 'view': 2, 'universal': 1, 'though': 1, 'some': 1, 'cases': 1, 'people': 1, 'specifically': 1, 'mean': 1, 'treating': 1, 'separate': 1, 'category': 1, 'initiatives': 1, 'help': 1, 'businesses': 1, 'increase': 1, 'revenues': 1, 'improve': 1, 'operational': 1, 'efficiency': 1, 'optimize': 1, 'marketing': 1, 'campaigns': 1, 'customer': 1, 'service': 1, 'efforts': 1, 'respond': 1, 'more': 2, 'quickly': 1, 'emerging': 1, 'market': 1, 'trends': 1, 'gain': 1, 'competitive': 1, 'edge': 1, 'over': 1, 'rivals': 1, 'ultimate': 1, 'goal': 1, 'boosting': 1, 'performance': 1, 'depending': 1, 'particular': 1, 'application': 1, 'analyzed': 1, 'consist': 1, 'either': 1, 'historical': 1, 'records': 1, 'information': 1, 'been': 1, 'processed': 1, 'real': 1, 'time': 1, 'addition': 1, 'come': 1, 'internal': 1, 'systems': 1, 'external': 1, 'sources': 1, 'high': 1, 'level': 1, 'methodologies': 1, 'include': 1, 'exploratory': 2, 'analysis': 6, 'which': 2, 'aims': 1, 'find': 1, 'patterns': 1, 'relationships': 1, 'confirmatory': 1, 'applies': 1, 'statistical': 1, 'techniques': 1, 'determine': 1, 'whether': 1, 'hypotheses': 1, 'about': 1, 'true': 1, 'false': 1, 'often': 1, 'compared': 2, 'detective': 1, 'work': 2, 'akin': 1, 'judge': 1, 'jury': 1, 'during': 1, 'court': 1, 'trial': 1, 'distinction': 1, 'first': 1, 'drawn': 1, 'statistician': 1, 'john': 1, 'tukey': 1, 'book': 1, 'also': 1, 'separated': 1, 'into': 1, 'quantitative': 1, 'qualitative': 2, 'former': 1, 'involves': 1, 'numerical': 2, 'quantifiable': 1, 'variables': 1, 'measured': 1, 'statistically': 1, 'approach': 1, 'interpretive': 1, 'focuses': 1, 'understanding': 1, 'content': 1, 'like': 1, 'text': 1, 'images': 1, 'audio': 1, 'video': 1, 'including': 1, 'common': 1, 'phrases': 1, 'themes': 1, 'points': 1}\n"
     ]
    }
   ],
   "source": [
    "# Q2: Frequency distribution of unique words\n",
    "import nltk\n",
    "# join into paragraph\n",
    "paragraph = \" \".join(lines_list2)\n",
    "nltk.download('punkt')\n",
    "words = nltk.tokenize.word_tokenize(paragraph)\n",
    "fdist1 = nltk.FreqDist(words)\n",
    "filtered_word_freq = dict((word, freq) for word, freq in fdist1.items() if not word.isdigit())\n",
    "print(filtered_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dca1b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(analytics_given_data): 0.04672897196261682\n"
     ]
    }
   ],
   "source": [
    "# Q3: probability of 'analytics' occurring given 'data'occurred in paragraph\n",
    "# Bayes theorem --> conditional probability\n",
    "paragraph = str.split(paragraph)\n",
    "tot_word = 0\n",
    "count_d = 0\n",
    "count_a = 0\n",
    "for lines in  paragraph:\n",
    "    tot_word = tot_word + 1\n",
    "    if lines == 'data':\n",
    "        count_d = count_d + 1\n",
    "    if lines == 'analytics':\n",
    "        count_a = count_a + 1\n",
    "prob_data = count_d / tot_word\n",
    "prob_analytics = count_a / tot_word\n",
    "print('P(analytics_given_data):',(prob_data*prob_analytics)/prob_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239390a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
